<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>逻辑回归</title>
      <link href="/2022/10/28/luo-ji-hui-gui-jiang-jie/"/>
      <url>/2022/10/28/luo-ji-hui-gui-jiang-jie/</url>
      
        <content type="html"><![CDATA[<h1>逻辑回归</h1><h2 id="1-模型介绍">1.模型介绍</h2><p>Logistic Regression 虽然被称为逻辑回归，但其实际上是分类模型，常用于二分类。具有一下三个特点:</p><ul><li>实现简单</li><li>可并行化</li><li>可解释性强</li></ul><h3 id="1-1-模型定义">1.1 模型定义</h3><p>对于0-1分类问题，概率建模如下：<br>$$p(y|x,\theta) =\frac{1}{1+e^{-\theta \cdot x}}$$</p><h3 id="1-2-损失函数推导">1.2 损失函数推导</h3><ul><li>极大似然估计</li><li>交叉熵</li></ul><h4 id="极大似然估计">极大似然估计</h4><blockquote><p>极大似然的原理</p></blockquote><blockquote><p>给定一个概率分布$D$，已知其概率密度函数（连续分布）或概率质量函数（离散分佈）为$f_D$，以及一个分佈参数$\theta$，我们可以从这个分布中抽出一个具有$n$个值的采样$X_1, X_2,\ldots, X_n$，利用$f_D$计算出其似然函数：$\mbox{L}(\theta\mid x_1,\dots,x_n) = f_\theta(x_1,\dots,x_n)$.</p><p>若$D$是离散分布，$f_\theta$即是在参数为$\theta$时观测到这一采样的概率。若其是连续分布，$f_\theta$则为$X_1, X_2,\ldots, X_n$联合分布的概率密度函数在观测值处的取值。一旦我们获得$X_1, X_2,\ldots, X_n$，我们就能求得一个关于$\theta$的估计。最大似然估计会寻找关于$\theta$的最可能的值（即，在所有可能的$\theta$取值中，寻找一个值使这个采样的“可能性”最大化）。从数学上来说，我们可以在$\theta$的所有可能取值中寻找一个值使得似然函数取到最大值。这个使可能性最大的$\widehat{\theta}$值即称为$\theta$的’‘‘最大似然估计’’'。</p><p><strong>注意</strong>:<br><em>这裡的似然函数是指$x_1,x_2,\ldots,x_n$不变时，关于$\theta$的一个函数</em>。<br><em>最大似然估计不一定存在，也不一定唯一</em>。</p></blockquote><p>事件为1发生的概率$p(y=1|x,\theta)=p$ ,事件为0发生的概率 $p(y=0|x,\theta)=1-p$<br>那么事件发生的概率可以写成：$p(y|x,\theta)={p^{y}}\cdot{(1-p)^{1-y}}$<br>利用极大似然估计,似然函数:$L(\theta)=\prod_i p_i(y^i|x^i,\theta)$,为简化求解，取对数似然，有：<br>$$<br>\begin{split}<br>lnL(\theta) &amp;= \sum_i lnp_i(y^i|x^i,\theta) \\<br>&amp;= \sum_i [y^{i}lnp_i + (1-y^i)ln(1-p_i)] \\<br>&amp;= \sum_i [y^{i}ln\frac{p_i}{1-p_i} + ln(1-p_i)] \\<br>&amp;= \sum_i [y^{i}(\theta \cdot x^i) - ln(1 + e^{\theta \cdot x^i})]<br>\end{split}<br>$$<br>最大化似然相当于最小化如下函数：<br>$$<br>\begin{align}<br>J(\theta) &amp;= -\frac{1}{N}lnL(\theta) \\<br>&amp;= -\frac{1}{N} \sum_i [y^{i}(\theta \cdot x^i) - ln(1 + e^{\theta \cdot x^i})]<br>\end{align}<br>$$</p><h4 id="交叉熵">交叉熵</h4><p>K-L散度：衡量两个分布$P,Q$之间的差异<br>$$<br>\begin{align}<br>D_{KL}(P \parallel Q) &amp;= \sum_{x \in \chi }P(x)log\frac{P(x)}{Q(x)} \\<br>&amp;= \sum_{x \in \chi }(P(x)log(P(x))+ P(x)log \frac{1}{Q(x)}) \\<br>&amp;= -H_P+H(P,Q) \\<br>KL散度 &amp;= -熵+ 交叉熵<br>\end{align}<br>$$</p><p>给定经验分布$P(y)$,我们要最小化模型分布$P_\theta(y)$与经验分布差异,即最小化二者的KL散度。回到公式定义，可以看出最小化KL散度等价于最小化交叉熵。交叉熵计算如下：<br>$$<br>\begin{align}<br>H(P(y|x,\theta_0),P_\theta(y|x,\theta)) &amp;= -\sum_{y \in {1,0}}P(y)logP_\theta(y) \\<br>&amp;= -[P(y=1)logP_\theta(y=1)+ (1-P(y=1))log (1-P_\theta(y=1))] \\<br>\end{align}<br>$$<br>通过采样,可以得到经验平均交叉熵:<br>$$<br>\begin{align}<br>\hat{H} &amp;= -\frac{1}{N}\sum_i [y^{i}logp_\theta(y^i) + (1-y^{i})log(1-p_\theta(y^i))] \\<br>\end{align}<br>$$</p><p><strong>我们从两个角度推出了同一个损失函数！</strong></p><h3 id="1-3-问题求解">1.3 问题求解</h3><p>无约束最优化问题：<br>$$<br>\begin{align}<br>\underset{\theta}{argmin}J(\theta)<br>\end{align}<br>$$<br>使用梯度下降算法求解:<br>$$<br>\begin{align}<br>\frac{\partial J(\theta)}{\partial \theta_i} &amp;= -\frac{1}{N}\sum_i[\frac{\partial y^{i}(\theta \cdot x^i)}{\partial \theta_i} - \frac{ln(1 + e^{\theta \cdot x^i})}{\partial \theta_i}] \\<br>&amp;=-\frac{1}{N}\sum_i y^ix_{i}^{i} + \sum_i \frac{x_{i}^{i}e^{\theta \cdot x^i}}{1+e^{\theta \cdot x^i}} \\<br>&amp;= \frac{1}{N}\sum_i (p_i-y^i)x_{i}^{i}<br>\end{align}<br>$$<br>参数更新公式:<br>$$<br>\begin{align}<br>\theta_{i}^{k+1} = \theta_{i}^{k} - \alpha\frac{\partial J(\theta)}{\partial \theta_i}<br>\end{align}<br>$$</p><h3 id="1-4-讨论">1.4 讨论</h3><ul><li>损失函数可以选择平方损失吗</li><li>极大似然估计与最小化交叉熵有什么联系</li></ul><h3 id="1-5-逻辑回归与在线学习">1.5 逻辑回归与在线学习</h3><h4 id="在线学习">在线学习</h4><p>在线学习 ( OnlineLearning ) 代表了一系列机器学习算法，特点是每来一个样本就能训练，能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。相比之下，传统的批处理方式需要一次性收集所有数据，新数据到来时重新训练的代价也很大，因而更新周期较长，可扩展性不高。<br>问题：稀疏性不好解决，随机梯度下降无法得到稀疏解(浮点运算，很难出现0值)<br>解决稀疏性的方法</p><ul><li>加入L1正则</li><li>简单截断,当梯度小于某个阈值时，强制归零</li><li>梯度截断<br>$$<br>\begin{equation}<br>T(x,\alpha,\theta)=<br>\begin{cases}<br>max(0,x-\alpha)&amp; {x \in [0,\theta]} \\<br>min(0,x+\alpha)&amp; {x \in [-\theta,0]} \\<br>x&amp; {其他} \<br>\end{cases}<br>\end{equation}<br>$$</li></ul>]]></content>
      
      
      <categories>
          
          <category> 统计机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo + github page 搭建个人博客</title>
      <link href="/2022/10/20/hello/"/>
      <url>/2022/10/20/hello/</url>
      
        <content type="html"><![CDATA[<h1>Hexo + github page 搭建个人博客</h1><h2 id="1-注册github账号">1.注册github账号</h2><p>首先去<a href="https://github.com">github官网</a>注册一个新号,用于托管我们的博客项目。</p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/10/20/hello-world/"/>
      <url>/2022/10/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start">Quick Start</h2><h3 id="Create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server">Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
